{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Is_Home_or_Away</th>\n",
       "      <th>Is_Opponent_in_AP25_Preseason</th>\n",
       "      <th>Media</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>9/2/17</td>\n",
       "      <td>Temple</td>\n",
       "      <td>Home</td>\n",
       "      <td>Out</td>\n",
       "      <td>1-NBC</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>9/9/17</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>Home</td>\n",
       "      <td>In</td>\n",
       "      <td>1-NBC</td>\n",
       "      <td>Lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>9/16/17</td>\n",
       "      <td>BostonCollege</td>\n",
       "      <td>Away</td>\n",
       "      <td>Out</td>\n",
       "      <td>2-ESPN</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>9/23/17</td>\n",
       "      <td>MichiganState</td>\n",
       "      <td>Away</td>\n",
       "      <td>Out</td>\n",
       "      <td>3-FOX</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>9/30/17</td>\n",
       "      <td>MiamiOhio</td>\n",
       "      <td>Home</td>\n",
       "      <td>Out</td>\n",
       "      <td>1-NBC</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Date       Opponent Is_Home_or_Away Is_Opponent_in_AP25_Preseason  \\\n",
       "0  25   9/2/17         Temple            Home                           Out   \n",
       "1  26   9/9/17        Georgia            Home                            In   \n",
       "2  27  9/16/17  BostonCollege            Away                           Out   \n",
       "3  28  9/23/17  MichiganState            Away                           Out   \n",
       "4  29  9/30/17      MiamiOhio            Home                           Out   \n",
       "\n",
       "    Media Label  \n",
       "0   1-NBC   Win  \n",
       "1   1-NBC  Lose  \n",
       "2  2-ESPN   Win  \n",
       "3   3-FOX   Win  \n",
       "4   1-NBC   Win  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_set=pd.read_csv(\"train.csv\")\n",
    "test_data_set=pd.read_csv(\"test.csv\")\n",
    "test_data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Is_Home_or_Away</th>\n",
       "      <th>Is_Opponent_in_AP25_Preseason</th>\n",
       "      <th>Media</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Home</td>\n",
       "      <td>Out</td>\n",
       "      <td>1-NBC</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>Away</td>\n",
       "      <td>Out</td>\n",
       "      <td>4-ABC</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>GeorgiaTech</td>\n",
       "      <td>Home</td>\n",
       "      <td>In</td>\n",
       "      <td>1-NBC</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>UMass</td>\n",
       "      <td>Home</td>\n",
       "      <td>Out</td>\n",
       "      <td>1-NBC</td>\n",
       "      <td>Win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Clemson</td>\n",
       "      <td>Away</td>\n",
       "      <td>In</td>\n",
       "      <td>4-ABC</td>\n",
       "      <td>Lose</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Opponent Is_Home_or_Away Is_Opponent_in_AP25_Preseason  Media Label\n",
       "0        Texas            Home                           Out  1-NBC   Win\n",
       "1     Virginia            Away                           Out  4-ABC   Win\n",
       "2  GeorgiaTech            Home                            In  1-NBC   Win\n",
       "3        UMass            Home                           Out  1-NBC   Win\n",
       "4      Clemson            Away                            In  4-ABC  Lose"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_set=train_data_set.drop([\"Date\",\"ID\"], axis=1)\n",
    "test_data_set=test_data_set.drop([\"Date\",\"ID\"], axis=1)\n",
    "train_data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Opponent</th>\n",
       "      <th>Is_Home_or_Away</th>\n",
       "      <th>Is_Opponent_in_AP25_Preseason</th>\n",
       "      <th>Media</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Opponent  Is_Home_or_Away  Is_Opponent_in_AP25_Preseason  Media  Label\n",
       "0        14                1                              1      0      1\n",
       "1        17                0                              1      3      1\n",
       "2         4                1                              0      0      1\n",
       "3        15                1                              1      0      1\n",
       "4         2                0                              0      3      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing categorical data to numerical\n",
    "\n",
    "for col in train_data_set.columns:\n",
    "    train_data_set[col]=pd.Categorical(train_data_set[col])\n",
    "    train_data_set[col]=train_data_set[col].cat.codes\n",
    "    \n",
    "train_data_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in test_data_set.columns:\n",
    "    test_data_set[col]=pd.Categorical(test_data_set[col])\n",
    "    test_data_set[col]=test_data_set[col].cat.codes\n",
    "    \n",
    "test_data_set=test_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  1,  1,  0],\n",
       "       [17,  0,  1,  3],\n",
       "       [ 4,  1,  0,  0],\n",
       "       [15,  1,  1,  0],\n",
       "       [ 2,  0,  0,  3],\n",
       "       [ 7,  1,  1,  0],\n",
       "       [16,  1,  0,  0],\n",
       "       [13,  0,  1,  3],\n",
       "       [10,  0,  1,  3],\n",
       "       [19,  1,  1,  0],\n",
       "       [ 1,  0,  1,  0],\n",
       "       [11,  0,  0,  2],\n",
       "       [14,  0,  1,  3],\n",
       "       [ 8,  1,  1,  0],\n",
       "       [ 6,  1,  1,  0],\n",
       "       [ 3,  1,  1,  0],\n",
       "       [12,  1,  1,  1],\n",
       "       [ 9,  0,  1,  3],\n",
       "       [11,  1,  0,  0],\n",
       "       [ 5,  1,  1,  0],\n",
       "       [ 7,  1,  1,  4],\n",
       "       [ 0,  1,  1,  0],\n",
       "       [18,  1,  0,  0],\n",
       "       [16,  0,  0,  3]], dtype=int8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ceating the training and testing data and labels\n",
    "\n",
    "train_x= train_data_set[train_data_set.columns[:-1]].values\n",
    "train_y=train_data_set['Label'].values\n",
    "train_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  1,  1,  0],\n",
       "       [ 1,  1,  0,  0],\n",
       "       [ 0,  0,  1,  1],\n",
       "       [ 4,  0,  1,  2],\n",
       "       [ 3,  1,  1,  0],\n",
       "       [ 6,  0,  1,  3],\n",
       "       [10,  1,  1,  0],\n",
       "       [ 7,  1,  1,  0],\n",
       "       [11,  1,  1,  0],\n",
       "       [ 2,  0,  0,  3],\n",
       "       [ 5,  1,  1,  0],\n",
       "       [ 8,  0,  0,  3]], dtype=int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x=test_data_set[test_data_set.columns[:-1]].values\n",
    "test_true_label=test_data_set[\"Label\"].values\n",
    "test_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive baiyes prediction\n",
    "\n",
    "model=GaussianNB()\n",
    "model.fit(np.array(train_x),train_y)\n",
    "predicted_labels=model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of accuracy and fscore\n",
    "\n",
    "def creatsum(name, y, y_pred):\n",
    "    headers = {\n",
    "        'Accuracy': accuracy_score, \n",
    "        'F1_Score': f1_score, \n",
    "        'Precision': precision_score, \n",
    "        'Recall': recall_score\n",
    "    }\n",
    "    \n",
    "    with open('{}.csv'.format(name), 'w') as summary:\n",
    "        print(','.join(headers.keys()), file=summary)\n",
    "        summary.write(','.join(['{:3.3f}'.format(metric(y, y_pred)) for metric in headers.values()]))\n",
    "\n",
    "#print(\"Accuracy\",metrics.accuracy_score(test_true_label,predicted_labels))\n",
    "creatsum(\"Nb\",test_true_label,predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.941</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1_Score  Precision  Recall\n",
       "0     0.917     0.941        1.0   0.889"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### the result obtain by using Naive Bayes Classificaiton\n",
    "\n",
    "Nb_summary=pd.read_csv(\"Nb.csv\")\n",
    "Nb_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1 Score  Precision  Recall\n",
       "0     0.833     0.889      0.889   0.889"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### the result obtain by previous assigment---- Decision tree by using ID3-----\n",
    "\n",
    "id_summary=pd.read_csv(\"id3.csv\")\n",
    "id_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1 Score  Precision  Recall\n",
       "0     0.917     0.947        0.9     1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### the result obtain by previous assigment---- Decision tree by using c4.5-----\n",
    "\n",
    "c45_summary=pd.read_csv(\"c45.csv\")\n",
    "c45_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "As we have calculated the f score accuracy etc in previous assigment on the same dataset with algorith like C4.5 and ID3\n",
    "\n",
    "from the above score we can observe that accuracy in case of Navie Bayes and C4.5 algorithm is same while the accuracy does go down in ID3\n",
    "\n",
    "\n",
    "from the above score we can come to a conclusion that Navie Bayes performs very well compared to Decision Tree and it's the best(when we consider precision and recall) while, ID3 alogrithm performs worst in all three.\n",
    "\n",
    "These could be due to following reasons.\n",
    "\n",
    "NB: work well with small dataset and has less overfitting while on the other hand decision tree need more dataset to perform well and algorithm like ID3 does not work well continuous and discrete features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------Link for code-------------\n",
    "https://github.com/rpm360/MLassignment/blob/master/HW4/MLHW4.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
